{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0080b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a220f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... started loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 32.44it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "base_model_name = \"Qwen/Qwen3-4B-Thinking-2507\"\n",
    "\n",
    "print('... started loading...')\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab261c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3Config {\n",
       "  \"architectures\": [\n",
       "    \"Qwen3ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"dtype\": \"bfloat16\",\n",
       "  \"eos_token_id\": 151645,\n",
       "  \"head_dim\": 128,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 2560,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 9728,\n",
       "  \"layer_types\": [\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\"\n",
       "  ],\n",
       "  \"max_position_embeddings\": 262144,\n",
       "  \"max_window_layers\": 36,\n",
       "  \"model_type\": \"qwen3\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 36,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 5000000,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"transformers_version\": \"4.57.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 151936\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2480955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9728"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.config.intermediate_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6729e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f0dab1-6dc3-4f8f-8095-39bec63fefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_position = torch.arange(0, 0 + 5, device='cpu'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c648d6e2-27af-441f-b556-91876237d92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0604b4-8e16-45c2-82a2-4cdffbacbfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
